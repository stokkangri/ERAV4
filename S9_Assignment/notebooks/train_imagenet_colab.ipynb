
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Training with ResNet-50\n",
    "\n",
    "This notebook provides a complete pipeline for training ResNet-50 on ImageNet-1k dataset with options for:\n",
    "- Training on small subset for quick experiments\n",
    "- Finding optimal learning rate using LR Finder\n",
    "- Full dataset training\n",
    "- Using pretrained weights\n",
    "- Replacing MaxPool with strided convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running on Google Colab\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "else:\n",
    "    print(\"Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install matplotlib tqdm scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone or setup the repository\n",
    "import os\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Option 1: Clone from GitHub (if you have uploaded the code)\n",
    "    # !git clone https://github.com/yourusername/S9_Assignment.git\n",
    "    # os.chdir('S9_Assignment')\n",
    "    \n",
    "    # Option 2: Copy from Google Drive (if you have uploaded the code)\n",
    "    # !cp -r /content/drive/MyDrive/S9_Assignment .\n",
    "    # os.chdir('S9_Assignment')\n",
    "    \n",
    "    # Option 3: Upload the files directly\n",
    "    print(\"Please upload the S9_Assignment folder to Colab or Google Drive\")\n",
    "    \n",
    "# Add the parent directory to path\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Import custom modules\n",
    "from models.resnet50_imagenet import resnet50\n",
    "from dataset.imagenet_loader import create_imagenet_loaders\n",
    "from utils.lr_finder import LRFinder\n",
    "from utils.train_test import train_epoch, test_epoch\n",
    "\n",
    "# Check CUDA availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "config = {\n",
    "    # Dataset\n",
    "    'dataset_type': 'small',  # Options: 'small', 'medium', 'full', 'tiny_imagenet'\n",
    "    'data_dir': '/content/imagenet',  # Update this path\n",
    "    'batch_size': 128,  # Reduce if GPU memory is limited\n",
    "    'num_workers': 4,\n",
    "    \n",
    "    # Model\n",
    "    'pretrained': False,  # Use pretrained weights\n",
    "    'replace_maxpool_with_conv': True,  # Replace MaxPool with Conv (default: True)\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 10,  # Increase for full training\n",
    "    'learning_rate': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 1e-4,\n",
    "    'scheduler': 'onecycle',  # Options: 'onecycle', 'cosine', 'step', None\n",
    "    \n",
    "    # LR Finder\n",
    "    'find_lr': True,  # Run LR finder before training\n",
    "    'lr_finder_iterations': 100,\n",
    "    \n",
    "    # Paths\n",
    "    'checkpoint_dir': './checkpoints',\n",
    "    'log_dir': './logs',\n",
    "    'plot_dir': './plots',\n",
    "}\n",
    "\n",
    "# Dataset size configurations\n",
    "dataset_configs = {\n",
    "    'small': {'subset_percent': 0.01, 'tiny_imagenet': False},  # 1% of ImageNet\n",
    "    'medium': {'subset_percent': 0.1, 'tiny_imagenet': False},  # 10% of ImageNet\n",
    "    'full': {'subset_percent': None, 'tiny_imagenet': False},   # Full ImageNet\n",
    "    'tiny_imagenet': {'subset_percent': None, 'tiny_imagenet': True}  # Tiny ImageNet\n",
    "}\n",
    "\n",
    "# Update config based on dataset type\n",
    "dataset_config = dataset_configs[config['dataset_type']]\n",
    "config.update(dataset_config)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download ImageNet Data (Instructions)\n",
    "\n",
    "### Option 1: Tiny ImageNet (Recommended for testing)\n",
    "Tiny ImageNet is a subset with 200 classes and smaller images (64x64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Tiny ImageNet (only if using tiny_imagenet)\n",
    "if config.get('tiny_imagenet', False):\n",
    "    !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "    !unzip -q tiny-imagenet-200.zip\n",
    "    !mv tiny-imagenet-200 /content/tiny-imagenet\n",
    "    config['data_dir'] = '/content/tiny-imagenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Full ImageNet-1k\n",
    "\n",
    "For full ImageNet-1k dataset:\n",
    "\n",
    "1. **Register and download from official source**: https://image-net.org/download.php\n",
    "2. **Required files**:\n",
    "   - Training images: `ILSVRC2012_img_train.tar` (~138GB)\n",
    "   - Validation images: `ILSVRC2012_img_val.tar` (~6.3GB)\n",
    "   - Development kit: `ILSVRC2012_devkit_t12.tar.gz`\n",
    "\n",
    "3. **Extract the data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands to extract ImageNet (run in terminal or adapt for Colab)\n",
    "# Note: This requires significant storage space (~150GB)\n",
    "\n",
    "# # Create directories\n",
    "# !mkdir -p /content/imagenet/train /content/imagenet/val\n",
    "\n",
    "# # Extract training data\n",
    "# !tar -xf ILSVRC2012_img_train.tar -C /content/imagenet/train/\n",
    "# !cd /content/imagenet/train && for f in *.tar; do mkdir -p \"${f%.tar}\" && tar -xf \"$f\" -C \"${f%.tar}\" && rm \"$f\"; done\n",
    "\n",
    "# # Extract validation data\n",
    "# !tar -xf ILSVRC2012_img_val.tar -C /content/imagenet/val/\n",
    "# # Use the validation ground truth to organize val images into folders\n",
    "# # You'll need the ILSVRC2012_validation_ground_truth.txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Use a subset for quick experiments\n",
    "\n",
    "If you have limited resources, you can:\n",
    "1. Use Tiny ImageNet (recommended)\n",
    "2. Use a small subset of ImageNet by setting `subset_percent` in config\n",
    "3. Create your own small dataset with a few classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader, val_loader, dataset_stats = create_imagenet_loaders(\n",
    "    data_dir=config['data_dir'],\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=config['num_workers'],\n",
    "    subset_percent=config.get('subset_percent', None),\n",
    "    tiny_imagenet=config.get('tiny_imagenet', False),\n",
    "    augment_train=True\n",
    ")\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "for key, value in dataset_stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = resnet50(\n",
    "    num_classes=dataset_stats['num_classes'],\n",
    "    pretrained=config['pretrained'],\n",
    "    replace_maxpool_with_conv=config['replace_maxpool_with_conv']\n",
    ")\n",
    "\n",
    "# Move to GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "# Multi-GPU training\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Learning Rate Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['find_lr']:\n",
    "    print(\"Running LR Finder...\")\n",
    "    \n",
    "    # Create criterion and temporary optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    temp_optimizer = optim.SGD(model.parameters(), lr=1e-7, momentum=0.9)\n",
    "    \n",
    "    # Create LR finder\n",
    "    lr_finder = LRFinder(model, temp_optimizer, criterion, device)\n",
    "    \n",
    "    # Run range test\n",
    "    lr_finder.range_test(\n",
    "        train_loader,\n",
    "        start_lr=1e-7,\n",
    "        end_lr=10,\n",
    "        num_iter=config['lr_finder_iterations'],\n",
    "        step_mode='exp'\n",
    "    )\n",
    "    \n",
    "    # Plot and find optimal LR\n",
    "    suggested_lr, min_loss_lr = lr_finder.plot_with_suggestion()\n",
    "    \n",
    "    print(f\"\\nSuggested LR: {suggested_lr:.2e}\")\n",
    "    print(f\"Min Loss LR: {min_loss_lr:.2e}\")\n",
    "    \n",
    "    # Update config with suggested LR\n",
    "    config['learning_rate'] = suggested_lr\n",
    "    config['max_lr'] = suggested_lr\n",
    "    \n",
    "    # Reset model\n",
    "    lr_finder.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    momentum=config['momentum'],\n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = None\n",
    "if config['scheduler'] == 'onecycle':\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=config.get('max_lr', config['learning_rate']),\n",
    "        epochs=config['epochs'],\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.3,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=25.0,\n",
    "        final_div_factor=10000.0\n",
    "    )\n",
    "elif config['scheduler'] == 'cosine':\n",
    "    scheduler = CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=config['epochs'],\n",
    "        eta_min=1e-6\n",
    "    )\n",
    "\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"Scheduler: {scheduler.__class__.__name__ if scheduler else 'None'}\")\n",
    "print(f\"Initial LR: {optimizer.param_groups[0]['lr']:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_acc_top5': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "# Best model tracking\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "# Create directories\n",
    "Path(config['checkpoint_dir']).mkdir(parents=True, exist_ok=True)\n",
    "Path(config['log_dir']).mkdir(parents=True, exist_ok=True)\n",
    "Path(config['plot_dir']).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"\\nStarting Training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    # Training phase\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, device, train_loader, optimizer, criterion,\n",
    "        scheduler if config['scheduler'] == 'onecycle' else None,\n",
    "        epoch, accumulation_steps=1, clip_grad_norm=None, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_acc, val_acc_top5, _ = test_epoch(\n",
    "        model, device, val_loader, criterion,\n",
    "        epoch, verbose=True, calc_top5=True\n",
    "    )\n",
    "    \n",
    "    # Update scheduler (for non-OneCycle)\n",
    "    if scheduler and config['scheduler'] != 'onecycle':\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Get current LR\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_acc_top5'].append(val_acc_top5)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'config': config\n",
    "        }, f\"{config['checkpoint_dir']}/best_model.pth\")\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['epochs']} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"  Val Top-5 Acc: {val_acc_top5:.2f}%\")\n",
    "    print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "    print(f\"  Best Val Acc: {best_val_acc:.2f}% (Epoch {best_epoch+1})\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nTraining Completed!\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.2f}% at Epoch {best_epoch+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Plot Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train')\n",
    "axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Val')\n",
    "axes[0, 0].set_title('Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0, 1].plot(epochs, history['train_acc'], 'b-', label='Train')\n",
    "axes[0, 1].plot(epochs, history['val_acc'], 'r-', label='Val Top-1')\n",
    "axes[0, 1].plot(epochs, history['val_acc_top5'], 'g-', label='Val Top-5')\n",
    "axes[0, 1].set_title('Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Learning rate plot\n",
    "axes[1, 0].plot(epochs, history['lr'], 'orange')\n",
    "axes[1, 0].set_title('Learning Rate')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('LR')\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Summary text\n",
    "axes[1, 1].axis('off')\n",
    "summary_text = f\"\"\"Training Summary:\n",
    "\n",
    "Dataset: {config['dataset_type']}\n",
    "Epochs: {config['epochs']}\n",
    "Batch Size: {config['batch_size']}\n",
    "\n",
    "Best Val Acc: {best_val_acc:.2f}%\n",
    "Best Epoch: {best_epoch + 1}\n",
    "\n",
    "Final Train Acc: {history['train_acc'][-1]:.2f}%\n",
    "Final Val Acc: {history['val_acc'][-1]:.2f}%\n",
    "Final Val Top-5: {history['val_acc_top5'][-1]:.2f}%\n",
    "\"\"\"\n",
    "axes[1, 1].text(0.1, 0.5, summary_text, fontsize=12, \n",
    "                verticalalignment='center', fontfamily='monospace')\n",
    "\n",
    "plt.suptitle('Training Progress', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config['plot_dir']}/training_curves.png\", dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "history_path = f\"{config['log_dir']}/training_history.json\"\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(history, f, indent=4)\n",
    "print(f\"Training history saved to {history_path}\")\n",
    "\n",
    "# Save configuration\n",
    "config_path = f\"{config['log_dir']}/config.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "print(f\"Configuration saved to {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(f\"{config['checkpoint_dir']}/best_model.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch'] + 1}\")\n",
    "\n",
    "# Final evaluation\n",
    "model.eval()\n",
    "val_loss, val_acc, val_acc_top5, _ = test_epoch(\n",
    "    model, device, val_loader, criterion,\n",
    "    epoch=checkpoint['epoch'], verbose=True, calc_top5=True\n",
    ")\n",
    "\n",
    "print(f\"\\nBest Model Performance:\")\n",
    "print(f\"  Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"  Validation Top-1 Accuracy: {val_acc:.2f}%\")\n",
    "print(f\"  Validation Top-5 Accuracy: {val_acc_top5:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of validation images\n",
    "model.eval()\n",
    "images, labels = next(iter(val_loader))\n",
    "images, labels = images[:8].to(device), labels[:8].to(device)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, predicted = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(8):\n",
    "    # Denormalize image for display\n",
    "    img = images[i].cpu()\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    img = img * std + mean\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    \n",
    "    # Display image\n",
    "    axes[i].imshow(img.permute(1, 2, 0))\n",
    "    axes[i].set_title(f'True: {labels[i].item()}\\nPred: {predicted[i, 0].item()}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Predictions', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}